#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•å•ä¸ªæ¨¡å‹çš„è¯Šæ–­è„šæœ¬
ç”¨æ³•: python test_model.py gpt-5-mini
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from backend.main import load_model_configs
from tester.latency_tester import LatencyTester


async def main():
    model_name = sys.argv[1] if len(sys.argv) > 1 else "gpt-5-mini"
    
    configs = load_model_configs()
    if model_name not in configs:
        print(f"âŒ æ¨¡å‹ '{model_name}' ä¸å­˜åœ¨")
        print(f"å¯ç”¨æ¨¡å‹: {list(configs.keys())}")
        return
    
    config = configs[model_name]
    print(f"ğŸ” æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"   Endpoint: {config.endpoint}")
    print(f"   API Version: {config.api_version}")
    print(f"   Stream: {config.stream}")
    print()
    
    tester = LatencyTester(request_timeout=30.0)
    test_question = "ä½ å¥½ï¼Œè¯·ç®€è¦è‡ªæˆ‘ä»‹ç»"
    
    print(f"ğŸ“¤ å‘é€è¯·æ±‚...\n")
    records = await tester.run_models([config], question=test_question)
    
    for record in records:
        print(f"âœ… å“åº”å®Œæˆ:")
        print(f"   å»¶è¿Ÿ: {record.latency_ms:.0f}ms")
        print(f"   çŠ¶æ€: {record.status}")
        if record.error:
            print(f"   âŒ é”™è¯¯: {record.error}")
        if record.response_text:
            print(f"   ğŸ“ å“åº”: {record.response_text[:200]}...")
        if record.total_tokens:
            print(f"   ğŸ“Š Tokens: {record.prompt_tokens} + {record.completion_tokens} = {record.total_tokens}")


if __name__ == "__main__":
    asyncio.run(main())
